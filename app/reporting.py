"""Reporting utilities for generating evaluation results."""

import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass
from jinja2 import Template

logger = logging.getLogger(__name__)


def redact_aws_account(s: str) -> str:
    """Redact AWS account numbers in ARNs and similar strings."""
    # Replace 12-digit numbers in ARNs with '***'
    return re.sub(r'(arn:aws:bedrock:[^:]+:)(\d{12})(:inference-profile/)', r'\1***\3', s)


@dataclass
class EvaluationResult:
    """Single evaluation result."""
    puzzle: str
    framework: str
    model: str
    run_number: int
    status: str  # "Pass" or "Fail"
    error_message: str | None = None
    execution_time: float | None = None


@dataclass
class EvaluationSummary:
    """Summary of all evaluation results."""
    results: List[EvaluationResult]
    total_runs: int
    timestamp: datetime



def collect_results(results: List[EvaluationResult]) -> Dict[str, Any]:
    """Organize results for reporting as: puzzle -> (framework, model) -> [statuses]."""
    organized = {}
    for result in results:
        puzzle_key = result.puzzle
        if puzzle_key not in organized:
            organized[puzzle_key] = {}
        key = (result.framework, result.model)
        if key not in organized[puzzle_key]:
            organized[puzzle_key][key] = []
        organized[puzzle_key][key].append(result.status)
    return organized


def generate_markdown_report(summary: EvaluationSummary, output_path: Path) -> None:
    """Generate a Markdown report suitable for GitHub Pages."""
    
    template_str = """# AgentGym Evaluation Results

Generated on: {{ timestamp }}

## Summary

Total evaluations: {{ total_runs }}

## Results by Puzzle

{% set status_emoji = {'Pass': '✅', 'Fail': '❌'} %}
{% for puzzle_name, results in organized_results.items() %}
### {{ puzzle_name | title }}

{% set max_runs = results.values() | map('length') | max %}
| Framework | Model {% for i in range(1, max_runs+1) %}| Run {{ i }} {% endfor %}| Success Rate |
|-----------|-------{% for i in range(1, max_runs+1) %}|-------{% endfor %}|--------------|
{% for (framework, model), runs in results.items() -%}
| {{ framework }} | {{ model }} {% for i in range(max_runs) %}| {{ status_emoji.get(runs[i], runs[i]) if runs|length > i else 'N/A' }} {% endfor %}| {{ ((runs | select('equalto', 'Pass') | list | length) / (runs|length) * 100) | round(1) if runs else 0 }}% |
{% endfor %}

{% endfor %}

## Detailed Results

{% for result in results %}
- **{{ result.puzzle }}** / {{ result.framework }} / {{ result.model }} / Run {{ result.run_number }}: {{ status_emoji.get(result.status, result.status) }}
{% if result.error_message %}  - Error: {{ result.error_message }}{% endif %}
{% if result.execution_time %}  - Time: {{ result.execution_time|round(2) }}s{% endif %}
{% endfor %}

---
*Generated by AgentGym evaluation framework*
"""

    organized_results = collect_results(summary.results)
    # Get frameworks from config (import here to avoid circular import)
    try:
        import config as agentgym_config
        frameworks = [framework for combo in agentgym_config.FRAMEWORK_MODEL_COMBINATIONS for framework in combo["frameworks"]]
    except Exception:
        frameworks = []
    # Redact AWS account numbers in organized_results and results
    def redact_model_keys(organized):
        out = {}
        for puzzle, results in organized.items():
            out[puzzle] = {}
            for (fw, model), v in results.items():
                out[puzzle][(fw, redact_aws_account(model))] = v
        return out

    redacted_organized = redact_model_keys(organized_results)
    redacted_results = []
    for r in summary.results:
        redacted_results.append(type(r)(
            **{**r.__dict__, 'model': redact_aws_account(r.model)}
        ))

    template = Template(template_str)
    content = template.render(
        timestamp=summary.timestamp.strftime("%Y-%m-%d %H:%M:%S"),
        total_runs=summary.total_runs,
        organized_results=redacted_organized,
        frameworks=frameworks,
        results=redacted_results
    )
    output_path.write_text(content)
    logger.info(f"📊 Markdown report generated: {output_path}")


def generate_json_report(summary: EvaluationSummary, output_path: Path) -> None:
    """Generate a JSON report for programmatic access."""
    
    # Convert tuple keys to string for JSON serialization
    def tuple_key_to_str_key(organized):
        out = {}
        for puzzle, results in organized.items():
            out[puzzle] = {f"{fw}|{model}": v for (fw, model), v in results.items()}
        return out

    # Redact AWS account numbers in models for JSON as well
    def redact_model_keys(organized):
        out = {}
        for puzzle, results in organized.items():
            out[puzzle] = {f"{fw}|{redact_aws_account(model)}": v for (fw, model), v in results.items()}
        return out

    organized_results = redact_model_keys(collect_results(summary.results))
    data = {
        "timestamp": summary.timestamp.isoformat(),
        "total_runs": summary.total_runs,
        "results": [
            {
                "puzzle": r.puzzle,
                "framework": r.framework,
                "model": redact_aws_account(r.model),
                "run_number": r.run_number,
                "status": r.status,
                "error_message": r.error_message,
                "execution_time": r.execution_time
            }
            for r in summary.results
        ],
        "organized_results": organized_results
    }
    output_path.write_text(json.dumps(data, indent=2))
    logger.info(f"📊 JSON report generated: {output_path}")


def save_reports(summary: EvaluationSummary, reports_dir: Path) -> None:
    """Save both Markdown and JSON reports."""
    reports_dir.mkdir(exist_ok=True)
    
    # Generate timestamp-based filenames
    timestamp_str = summary.timestamp.strftime("%Y%m%d_%H%M%S")
    
    # Save timestamped versions
    generate_markdown_report(summary, reports_dir / f"results_{timestamp_str}.md")
    generate_json_report(summary, reports_dir / f"results_{timestamp_str}.json")
    
    # Save latest versions (for GitHub Pages)
    generate_markdown_report(summary, reports_dir / "latest.md")
    generate_json_report(summary, reports_dir / "latest.json")
    
    logger.info(f"📊 Reports saved to {reports_dir}")
